{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS region:us-east-1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "# #same function\n",
    "# sess = sage.Session()\n",
    "\n",
    "role = 'arn:aws:iam::002224604296:role/service-role/AmazonSageMaker-ExecutionRole-20200402T124851'\n",
    "aws_region = session.region_name\n",
    "print(f'AWS region:{aws_region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-25 08:22:29 Starting - Starting the training job...\n",
      "2020-11-25 08:22:31 Starting - Launching requested ML instances.........\n",
      "2020-11-25 08:24:05 Starting - Preparing the instances for training......\n",
      "2020-11-25 08:25:23 Downloading - Downloading input data\n",
      "2020-11-25 08:25:23 Training - Downloading the training image..................\n",
      "2020-11-25 08:28:29 Training - Training image download completed. Training in progress..\u001b[34msys path is ['/opt/ml/code', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/src/fasthan', '/src/dglke/python', '/usr/lib/python3/dist-packages']\u001b[0m\n",
      "\u001b[34mUsing backend: pytorch\u001b[0m\n",
      "\u001b[34mReading train triples....\u001b[0m\n",
      "\u001b[34mFinished. Read 3603022 train triples.\u001b[0m\n",
      "\u001b[34m|Train|: 3603022\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.\n",
      "  warnings.warn(msg, warn_type)\u001b[0m\n",
      "\u001b[34mTotal initialize time 8.594 seconds\u001b[0m\n",
      "\u001b[34m[proc 0][Train](2/200) average pos_loss: 2.87387216091156\u001b[0m\n",
      "\u001b[34m[proc 0][Train](2/200) average neg_loss: 0.4520792067050934\u001b[0m\n",
      "\u001b[34m[proc 0][Train](2/200) average loss: 1.6629756689071655\u001b[0m\n",
      "\u001b[34m[proc 0][Train](2/200) average regularization: 6.236725312191993e-06\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.481 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.250, forward: 0.150, backward: 0.062, update: 0.019\u001b[0m\n",
      "\u001b[34m[proc 0][Train](4/200) average pos_loss: 2.819865584373474\u001b[0m\n",
      "\u001b[34m[proc 0][Train](4/200) average neg_loss: 0.5068945288658142\u001b[0m\n",
      "\u001b[34m[proc 0][Train](4/200) average loss: 1.6633800268173218\u001b[0m\n",
      "\u001b[34m[proc 0][Train](4/200) average regularization: 1.8344186628382886e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](6/200) average pos_loss: 2.7204662561416626\u001b[0m\n",
      "\u001b[34m[proc 0][Train](6/200) average neg_loss: 0.6139809042215347\u001b[0m\n",
      "\u001b[34m[proc 0][Train](6/200) average loss: 1.667223572731018\u001b[0m\n",
      "\u001b[34m[proc 0][Train](6/200) average regularization: 2.4928076527430676e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](8/200) average pos_loss: 2.747694253921509\u001b[0m\n",
      "\u001b[34m[proc 0][Train](8/200) average neg_loss: 0.5616453588008881\u001b[0m\n",
      "\u001b[34m[proc 0][Train](8/200) average loss: 1.6546697616577148\u001b[0m\n",
      "\u001b[34m[proc 0][Train](8/200) average regularization: 2.6745352442958392e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](10/200) average pos_loss: 2.8826379776000977\u001b[0m\n",
      "\u001b[34m[proc 0][Train](10/200) average neg_loss: 0.5701107382774353\u001b[0m\n",
      "\u001b[34m[proc 0][Train](10/200) average loss: 1.726374328136444\u001b[0m\n",
      "\u001b[34m[proc 0][Train](10/200) average regularization: 2.7903419322683476e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](12/200) average pos_loss: 2.708869457244873\u001b[0m\n",
      "\u001b[34m[proc 0][Train](12/200) average neg_loss: 0.6523617804050446\u001b[0m\n",
      "\u001b[34m[proc 0][Train](12/200) average loss: 1.6806156039237976\u001b[0m\n",
      "\u001b[34m[proc 0][Train](12/200) average regularization: 2.9069445190543775e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](14/200) average pos_loss: 2.767373561859131\u001b[0m\n",
      "\u001b[34m[proc 0][Train](14/200) average neg_loss: 0.7138729989528656\u001b[0m\n",
      "\u001b[34m[proc 0][Train](14/200) average loss: 1.7406232953071594\u001b[0m\n",
      "\u001b[34m[proc 0][Train](14/200) average regularization: 3.00547580991406e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](16/200) average pos_loss: 2.9274336099624634\u001b[0m\n",
      "\u001b[34m[proc 0][Train](16/200) average neg_loss: 0.6238171756267548\u001b[0m\n",
      "\u001b[34m[proc 0][Train](16/200) average loss: 1.7756253480911255\u001b[0m\n",
      "\u001b[34m[proc 0][Train](16/200) average regularization: 3.451430347922724e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](18/200) average pos_loss: 2.9967143535614014\u001b[0m\n",
      "\u001b[34m[proc 0][Train](18/200) average neg_loss: 0.6878419816493988\u001b[0m\n",
      "\u001b[34m[proc 0][Train](18/200) average loss: 1.8422781825065613\u001b[0m\n",
      "\u001b[34m[proc 0][Train](18/200) average regularization: 3.517874574754387e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.098 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.020, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](20/200) average pos_loss: 3.191122531890869\u001b[0m\n",
      "\u001b[34m[proc 0][Train](20/200) average neg_loss: 0.6825242042541504\u001b[0m\n",
      "\u001b[34m[proc 0][Train](20/200) average loss: 1.936823308467865\u001b[0m\n",
      "\u001b[34m[proc 0][Train](20/200) average regularization: 3.506704706524033e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.085 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.039, update: 0.007\u001b[0m\n",
      "\u001b[34m[proc 0][Train](22/200) average pos_loss: 3.1114038228988647\u001b[0m\n",
      "\u001b[34m[proc 0][Train](22/200) average neg_loss: 0.8190679848194122\u001b[0m\n",
      "\u001b[34m[proc 0][Train](22/200) average loss: 1.965235948562622\u001b[0m\n",
      "\u001b[34m[proc 0][Train](22/200) average regularization: 3.7004519981564954e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.085 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.003, forward: 0.039, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](24/200) average pos_loss: 3.020856499671936\u001b[0m\n",
      "\u001b[34m[proc 0][Train](24/200) average neg_loss: 0.7023048847913742\u001b[0m\n",
      "\u001b[34m[proc 0][Train](24/200) average loss: 1.8615806698799133\u001b[0m\n",
      "\u001b[34m[proc 0][Train](24/200) average regularization: 3.8471518564620055e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](26/200) average pos_loss: 3.1300532817840576\u001b[0m\n",
      "\u001b[34m[proc 0][Train](26/200) average neg_loss: 0.7562656402587891\u001b[0m\n",
      "\u001b[34m[proc 0][Train](26/200) average loss: 1.9431594014167786\u001b[0m\n",
      "\u001b[34m[proc 0][Train](26/200) average regularization: 4.137792348046787e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](28/200) average pos_loss: 3.097927451133728\u001b[0m\n",
      "\u001b[34m[proc 0][Train](28/200) average neg_loss: 0.6584884077310562\u001b[0m\n",
      "\u001b[34m[proc 0][Train](28/200) average loss: 1.8782079815864563\u001b[0m\n",
      "\u001b[34m[proc 0][Train](28/200) average regularization: 3.8712674722773954e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](30/200) average pos_loss: 3.122005820274353\u001b[0m\n",
      "\u001b[34m[proc 0][Train](30/200) average neg_loss: 0.7530407905578613\u001b[0m\n",
      "\u001b[34m[proc 0][Train](30/200) average loss: 1.937523365020752\u001b[0m\n",
      "\u001b[34m[proc 0][Train](30/200) average regularization: 4.183981764072087e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.007\u001b[0m\n",
      "\u001b[34m[proc 0][Train](32/200) average pos_loss: 3.149812936782837\u001b[0m\n",
      "\u001b[34m[proc 0][Train](32/200) average neg_loss: 0.7117214500904083\u001b[0m\n",
      "\u001b[34m[proc 0][Train](32/200) average loss: 1.9307671189308167\u001b[0m\n",
      "\u001b[34m[proc 0][Train](32/200) average regularization: 3.9783706597518176e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](34/200) average pos_loss: 3.37248694896698\u001b[0m\n",
      "\u001b[34m[proc 0][Train](34/200) average neg_loss: 0.7442639321088791\u001b[0m\n",
      "\u001b[34m[proc 0][Train](34/200) average loss: 2.058375358581543\u001b[0m\n",
      "\u001b[34m[proc 0][Train](34/200) average regularization: 4.193338281766046e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.098 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.021, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](36/200) average pos_loss: 3.241294503211975\u001b[0m\n",
      "\u001b[34m[proc 0][Train](36/200) average neg_loss: 0.723387211561203\u001b[0m\n",
      "\u001b[34m[proc 0][Train](36/200) average loss: 1.9823408126831055\u001b[0m\n",
      "\u001b[34m[proc 0][Train](36/200) average regularization: 3.9832297261455096e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](38/200) average pos_loss: 3.4452853202819824\u001b[0m\n",
      "\u001b[34m[proc 0][Train](38/200) average neg_loss: 0.7472240179777145\u001b[0m\n",
      "\u001b[34m[proc 0][Train](38/200) average loss: 2.0962546467781067\u001b[0m\n",
      "\u001b[34m[proc 0][Train](38/200) average regularization: 3.865779945044778e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](40/200) average pos_loss: 3.4679031372070312\u001b[0m\n",
      "\u001b[34m[proc 0][Train](40/200) average neg_loss: 0.7564820945262909\u001b[0m\n",
      "\u001b[34m[proc 0][Train](40/200) average loss: 2.1121926307678223\u001b[0m\n",
      "\u001b[34m[proc 0][Train](40/200) average regularization: 4.573779915517662e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](42/200) average pos_loss: 3.393344283103943\u001b[0m\n",
      "\u001b[34m[proc 0][Train](42/200) average neg_loss: 0.7493642121553421\u001b[0m\n",
      "\u001b[34m[proc 0][Train](42/200) average loss: 2.0713542699813843\u001b[0m\n",
      "\u001b[34m[proc 0][Train](42/200) average regularization: 4.601197906595189e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](44/200) average pos_loss: 3.253767967224121\u001b[0m\n",
      "\u001b[34m[proc 0][Train](44/200) average neg_loss: 0.8764660060405731\u001b[0m\n",
      "\u001b[34m[proc 0][Train](44/200) average loss: 2.065117061138153\u001b[0m\n",
      "\u001b[34m[proc 0][Train](44/200) average regularization: 4.6688210204592906e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](46/200) average pos_loss: 3.507445216178894\u001b[0m\n",
      "\u001b[34m[proc 0][Train](46/200) average neg_loss: 0.7768340408802032\u001b[0m\n",
      "\u001b[34m[proc 0][Train](46/200) average loss: 2.1421395540237427\u001b[0m\n",
      "\u001b[34m[proc 0][Train](46/200) average regularization: 5.274303657643031e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](48/200) average pos_loss: 3.5905704498291016\u001b[0m\n",
      "\u001b[34m[proc 0][Train](48/200) average neg_loss: 0.7982446551322937\u001b[0m\n",
      "\u001b[34m[proc 0][Train](48/200) average loss: 2.1944074630737305\u001b[0m\n",
      "\u001b[34m[proc 0][Train](48/200) average regularization: 4.5387518184725195e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](50/200) average pos_loss: 3.6575080156326294\u001b[0m\n",
      "\u001b[34m[proc 0][Train](50/200) average neg_loss: 0.7865004539489746\u001b[0m\n",
      "\u001b[34m[proc 0][Train](50/200) average loss: 2.2220042943954468\u001b[0m\n",
      "\u001b[34m[proc 0][Train](50/200) average regularization: 4.150983295403421e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.105 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.026, forward: 0.037, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](52/200) average pos_loss: 3.667458415031433\u001b[0m\n",
      "\u001b[34m[proc 0][Train](52/200) average neg_loss: 0.8970824480056763\u001b[0m\n",
      "\u001b[34m[proc 0][Train](52/200) average loss: 2.2822704315185547\u001b[0m\n",
      "\u001b[34m[proc 0][Train](52/200) average regularization: 4.582472683978267e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](54/200) average pos_loss: 3.6373379230499268\u001b[0m\n",
      "\u001b[34m[proc 0][Train](54/200) average neg_loss: 0.9652323424816132\u001b[0m\n",
      "\u001b[34m[proc 0][Train](54/200) average loss: 2.3012850284576416\u001b[0m\n",
      "\u001b[34m[proc 0][Train](54/200) average regularization: 4.659900878323242e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.083 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](56/200) average pos_loss: 4.006515264511108\u001b[0m\n",
      "\u001b[34m[proc 0][Train](56/200) average neg_loss: 0.7578544020652771\u001b[0m\n",
      "\u001b[34m[proc 0][Train](56/200) average loss: 2.3821847438812256\u001b[0m\n",
      "\u001b[34m[proc 0][Train](56/200) average regularization: 4.291859659133479e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](58/200) average pos_loss: 3.7606993913650513\u001b[0m\n",
      "\u001b[34m[proc 0][Train](58/200) average neg_loss: 0.8680441677570343\u001b[0m\n",
      "\u001b[34m[proc 0][Train](58/200) average loss: 2.314371705055237\u001b[0m\n",
      "\u001b[34m[proc 0][Train](58/200) average regularization: 4.657229692384135e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](60/200) average pos_loss: 3.617333173751831\u001b[0m\n",
      "\u001b[34m[proc 0][Train](60/200) average neg_loss: 0.9958997368812561\u001b[0m\n",
      "\u001b[34m[proc 0][Train](60/200) average loss: 2.306616425514221\u001b[0m\n",
      "\u001b[34m[proc 0][Train](60/200) average regularization: 4.673591138271149e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](62/200) average pos_loss: 3.9987993240356445\u001b[0m\n",
      "\u001b[34m[proc 0][Train](62/200) average neg_loss: 0.8825615048408508\u001b[0m\n",
      "\u001b[34m[proc 0][Train](62/200) average loss: 2.4406803846359253\u001b[0m\n",
      "\u001b[34m[proc 0][Train](62/200) average regularization: 4.327957140048966e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](64/200) average pos_loss: 3.9337894916534424\u001b[0m\n",
      "\u001b[34m[proc 0][Train](64/200) average neg_loss: 0.9667389690876007\u001b[0m\n",
      "\u001b[34m[proc 0][Train](64/200) average loss: 2.4502642154693604\u001b[0m\n",
      "\u001b[34m[proc 0][Train](64/200) average regularization: 4.525134863797575e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](66/200) average pos_loss: 4.208735466003418\u001b[0m\n",
      "\u001b[34m[proc 0][Train](66/200) average neg_loss: 0.8502474725246429\u001b[0m\n",
      "\u001b[34m[proc 0][Train](66/200) average loss: 2.5294915437698364\u001b[0m\n",
      "\u001b[34m[proc 0][Train](66/200) average regularization: 4.6904035116313025e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.098 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.021, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](68/200) average pos_loss: 4.0878050327301025\u001b[0m\n",
      "\u001b[34m[proc 0][Train](68/200) average neg_loss: 0.892597883939743\u001b[0m\n",
      "\u001b[34m[proc 0][Train](68/200) average loss: 2.490201473236084\u001b[0m\n",
      "\u001b[34m[proc 0][Train](68/200) average regularization: 4.9425438191974536e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](70/200) average pos_loss: 3.9270577430725098\u001b[0m\n",
      "\u001b[34m[proc 0][Train](70/200) average neg_loss: 0.8904862999916077\u001b[0m\n",
      "\u001b[34m[proc 0][Train](70/200) average loss: 2.408772110939026\u001b[0m\n",
      "\u001b[34m[proc 0][Train](70/200) average regularization: 5.1374241593293846e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](72/200) average pos_loss: 3.972738027572632\u001b[0m\n",
      "\u001b[34m[proc 0][Train](72/200) average neg_loss: 0.9021202325820923\u001b[0m\n",
      "\u001b[34m[proc 0][Train](72/200) average loss: 2.4374290704727173\u001b[0m\n",
      "\u001b[34m[proc 0][Train](72/200) average regularization: 5.5040596635080874e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](74/200) average pos_loss: 4.102581024169922\u001b[0m\n",
      "\u001b[34m[proc 0][Train](74/200) average neg_loss: 0.8987597823143005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](74/200) average loss: 2.5006704330444336\u001b[0m\n",
      "\u001b[34m[proc 0][Train](74/200) average regularization: 5.201318344916217e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.079 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](76/200) average pos_loss: 4.103346228599548\u001b[0m\n",
      "\u001b[34m[proc 0][Train](76/200) average neg_loss: 0.9190825819969177\u001b[0m\n",
      "\u001b[34m[proc 0][Train](76/200) average loss: 2.5112143754959106\u001b[0m\n",
      "\u001b[34m[proc 0][Train](76/200) average regularization: 4.1086597775574774e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](78/200) average pos_loss: 4.074411869049072\u001b[0m\n",
      "\u001b[34m[proc 0][Train](78/200) average neg_loss: 0.8646070659160614\u001b[0m\n",
      "\u001b[34m[proc 0][Train](78/200) average loss: 2.469509482383728\u001b[0m\n",
      "\u001b[34m[proc 0][Train](78/200) average regularization: 5.175658043299336e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](80/200) average pos_loss: 4.0483927726745605\u001b[0m\n",
      "\u001b[34m[proc 0][Train](80/200) average neg_loss: 0.9419947564601898\u001b[0m\n",
      "\u001b[34m[proc 0][Train](80/200) average loss: 2.4951937198638916\u001b[0m\n",
      "\u001b[34m[proc 0][Train](80/200) average regularization: 4.712332884082571e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](82/200) average pos_loss: 4.109050989151001\u001b[0m\n",
      "\u001b[34m[proc 0][Train](82/200) average neg_loss: 0.9652725160121918\u001b[0m\n",
      "\u001b[34m[proc 0][Train](82/200) average loss: 2.5371618270874023\u001b[0m\n",
      "\u001b[34m[proc 0][Train](82/200) average regularization: 5.451847391668707e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.098 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.020, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](84/200) average pos_loss: 4.286998510360718\u001b[0m\n",
      "\u001b[34m[proc 0][Train](84/200) average neg_loss: 0.871163547039032\u001b[0m\n",
      "\u001b[34m[proc 0][Train](84/200) average loss: 2.5790810585021973\u001b[0m\n",
      "\u001b[34m[proc 0][Train](84/200) average regularization: 4.321036431065295e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](86/200) average pos_loss: 4.312464475631714\u001b[0m\n",
      "\u001b[34m[proc 0][Train](86/200) average neg_loss: 0.9730085134506226\u001b[0m\n",
      "\u001b[34m[proc 0][Train](86/200) average loss: 2.6427364349365234\u001b[0m\n",
      "\u001b[34m[proc 0][Train](86/200) average regularization: 5.4805852414574474e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](88/200) average pos_loss: 4.361468076705933\u001b[0m\n",
      "\u001b[34m[proc 0][Train](88/200) average neg_loss: 0.9513702392578125\u001b[0m\n",
      "\u001b[34m[proc 0][Train](88/200) average loss: 2.6564191579818726\u001b[0m\n",
      "\u001b[34m[proc 0][Train](88/200) average regularization: 4.937765152135398e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](90/200) average pos_loss: 4.424827337265015\u001b[0m\n",
      "\u001b[34m[proc 0][Train](90/200) average neg_loss: 0.9333950579166412\u001b[0m\n",
      "\u001b[34m[proc 0][Train](90/200) average loss: 2.6791112422943115\u001b[0m\n",
      "\u001b[34m[proc 0][Train](90/200) average regularization: 4.977612479706295e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](92/200) average pos_loss: 4.461948394775391\u001b[0m\n",
      "\u001b[34m[proc 0][Train](92/200) average neg_loss: 0.7958707511425018\u001b[0m\n",
      "\u001b[34m[proc 0][Train](92/200) average loss: 2.6289095878601074\u001b[0m\n",
      "\u001b[34m[proc 0][Train](92/200) average regularization: 4.730864748125896e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](94/200) average pos_loss: 4.482961893081665\u001b[0m\n",
      "\u001b[34m[proc 0][Train](94/200) average neg_loss: 1.055062472820282\u001b[0m\n",
      "\u001b[34m[proc 0][Train](94/200) average loss: 2.769012212753296\u001b[0m\n",
      "\u001b[34m[proc 0][Train](94/200) average regularization: 4.4607686504605226e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](96/200) average pos_loss: 4.329347133636475\u001b[0m\n",
      "\u001b[34m[proc 0][Train](96/200) average neg_loss: 0.9959743022918701\u001b[0m\n",
      "\u001b[34m[proc 0][Train](96/200) average loss: 2.662660598754883\u001b[0m\n",
      "\u001b[34m[proc 0][Train](96/200) average regularization: 4.966035521647427e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](98/200) average pos_loss: 4.467733383178711\u001b[0m\n",
      "\u001b[34m[proc 0][Train](98/200) average neg_loss: 0.9128458797931671\u001b[0m\n",
      "\u001b[34m[proc 0][Train](98/200) average loss: 2.690289616584778\u001b[0m\n",
      "\u001b[34m[proc 0][Train](98/200) average regularization: 4.423004611453507e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.105 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.027, forward: 0.037, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](100/200) average pos_loss: 4.294316291809082\u001b[0m\n",
      "\u001b[34m[proc 0][Train](100/200) average neg_loss: 0.9416537582874298\u001b[0m\n",
      "\u001b[34m[proc 0][Train](100/200) average loss: 2.6179850101470947\u001b[0m\n",
      "\u001b[34m[proc 0][Train](100/200) average regularization: 4.709241875389125e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](102/200) average pos_loss: 4.690890312194824\u001b[0m\n",
      "\u001b[34m[proc 0][Train](102/200) average neg_loss: 1.011904627084732\u001b[0m\n",
      "\u001b[34m[proc 0][Train](102/200) average loss: 2.851397395133972\u001b[0m\n",
      "\u001b[34m[proc 0][Train](102/200) average regularization: 4.5549561036750674e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](104/200) average pos_loss: 4.767392873764038\u001b[0m\n",
      "\u001b[34m[proc 0][Train](104/200) average neg_loss: 0.9143267869949341\u001b[0m\n",
      "\u001b[34m[proc 0][Train](104/200) average loss: 2.840859889984131\u001b[0m\n",
      "\u001b[34m[proc 0][Train](104/200) average regularization: 4.735077527584508e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](106/200) average pos_loss: 4.731170177459717\u001b[0m\n",
      "\u001b[34m[proc 0][Train](106/200) average neg_loss: 0.9521358609199524\u001b[0m\n",
      "\u001b[34m[proc 0][Train](106/200) average loss: 2.8416531085968018\u001b[0m\n",
      "\u001b[34m[proc 0][Train](106/200) average regularization: 4.8610208978061564e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](108/200) average pos_loss: 4.640475511550903\u001b[0m\n",
      "\u001b[34m[proc 0][Train](108/200) average neg_loss: 1.1422770321369171\u001b[0m\n",
      "\u001b[34m[proc 0][Train](108/200) average loss: 2.891376256942749\u001b[0m\n",
      "\u001b[34m[proc 0][Train](108/200) average regularization: 5.141937253938522e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[proc 0][Train](110/200) average pos_loss: 4.572944641113281\u001b[0m\n",
      "\u001b[34m[proc 0][Train](110/200) average neg_loss: 1.0468179881572723\u001b[0m\n",
      "\u001b[34m[proc 0][Train](110/200) average loss: 2.809881329536438\u001b[0m\n",
      "\u001b[34m[proc 0][Train](110/200) average regularization: 5.2557668823283166e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](112/200) average pos_loss: 4.56855583190918\u001b[0m\n",
      "\u001b[34m[proc 0][Train](112/200) average neg_loss: 0.9784812927246094\u001b[0m\n",
      "\u001b[34m[proc 0][Train](112/200) average loss: 2.7735185623168945\u001b[0m\n",
      "\u001b[34m[proc 0][Train](112/200) average regularization: 5.3353198381955735e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](114/200) average pos_loss: 4.854580879211426\u001b[0m\n",
      "\u001b[34m[proc 0][Train](114/200) average neg_loss: 0.9834300577640533\u001b[0m\n",
      "\u001b[34m[proc 0][Train](114/200) average loss: 2.919005513191223\u001b[0m\n",
      "\u001b[34m[proc 0][Train](114/200) average regularization: 5.2667925046989694e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.099 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.021, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](116/200) average pos_loss: 4.450170993804932\u001b[0m\n",
      "\u001b[34m[proc 0][Train](116/200) average neg_loss: 0.9632972478866577\u001b[0m\n",
      "\u001b[34m[proc 0][Train](116/200) average loss: 2.70673406124115\u001b[0m\n",
      "\u001b[34m[proc 0][Train](116/200) average regularization: 5.219314698479138e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](118/200) average pos_loss: 4.962653398513794\u001b[0m\n",
      "\u001b[34m[proc 0][Train](118/200) average neg_loss: 0.9832419455051422\u001b[0m\n",
      "\u001b[34m[proc 0][Train](118/200) average loss: 2.9729477167129517\u001b[0m\n",
      "\u001b[34m[proc 0][Train](118/200) average regularization: 5.210276140132919e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](120/200) average pos_loss: 5.025018930435181\u001b[0m\n",
      "\u001b[34m[proc 0][Train](120/200) average neg_loss: 1.0753008127212524\u001b[0m\n",
      "\u001b[34m[proc 0][Train](120/200) average loss: 3.0501598119735718\u001b[0m\n",
      "\u001b[34m[proc 0][Train](120/200) average regularization: 4.987083957530558e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](122/200) average pos_loss: 4.805213689804077\u001b[0m\n",
      "\u001b[34m[proc 0][Train](122/200) average neg_loss: 0.9823789596557617\u001b[0m\n",
      "\u001b[34m[proc 0][Train](122/200) average loss: 2.8937963247299194\u001b[0m\n",
      "\u001b[34m[proc 0][Train](122/200) average regularization: 4.9215763283427805e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](124/200) average pos_loss: 5.132292985916138\u001b[0m\n",
      "\u001b[34m[proc 0][Train](124/200) average neg_loss: 0.978428840637207\u001b[0m\n",
      "\u001b[34m[proc 0][Train](124/200) average loss: 3.0553609132766724\u001b[0m\n",
      "\u001b[34m[proc 0][Train](124/200) average regularization: 5.067994243290741e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](126/200) average pos_loss: 4.994137287139893\u001b[0m\n",
      "\u001b[34m[proc 0][Train](126/200) average neg_loss: 1.11578968167305\u001b[0m\n",
      "\u001b[34m[proc 0][Train](126/200) average loss: 3.05496346950531\u001b[0m\n",
      "\u001b[34m[proc 0][Train](126/200) average regularization: 4.616600745066535e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](128/200) average pos_loss: 4.957947254180908\u001b[0m\n",
      "\u001b[34m[proc 0][Train](128/200) average neg_loss: 1.1129635572433472\u001b[0m\n",
      "\u001b[34m[proc 0][Train](128/200) average loss: 3.0354554653167725\u001b[0m\n",
      "\u001b[34m[proc 0][Train](128/200) average regularization: 5.495086588780396e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.089 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.043, backward: 0.039, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](130/200) average pos_loss: 4.993550777435303\u001b[0m\n",
      "\u001b[34m[proc 0][Train](130/200) average neg_loss: 1.127062827348709\u001b[0m\n",
      "\u001b[34m[proc 0][Train](130/200) average loss: 3.0603069067001343\u001b[0m\n",
      "\u001b[34m[proc 0][Train](130/200) average regularization: 5.285051520331763e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.098 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.020, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](132/200) average pos_loss: 4.887897491455078\u001b[0m\n",
      "\u001b[34m[proc 0][Train](132/200) average neg_loss: 0.9975640177726746\u001b[0m\n",
      "\u001b[34m[proc 0][Train](132/200) average loss: 2.9427307844161987\u001b[0m\n",
      "\u001b[34m[proc 0][Train](132/200) average regularization: 5.391336162574589e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](134/200) average pos_loss: 4.996899127960205\u001b[0m\n",
      "\u001b[34m[proc 0][Train](134/200) average neg_loss: 0.8921166956424713\u001b[0m\n",
      "\u001b[34m[proc 0][Train](134/200) average loss: 2.9445079565048218\u001b[0m\n",
      "\u001b[34m[proc 0][Train](134/200) average regularization: 5.471674921864178e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](136/200) average pos_loss: 4.89634370803833\u001b[0m\n",
      "\u001b[34m[proc 0][Train](136/200) average neg_loss: 1.0945460200309753\u001b[0m\n",
      "\u001b[34m[proc 0][Train](136/200) average loss: 2.9954447746276855\u001b[0m\n",
      "\u001b[34m[proc 0][Train](136/200) average regularization: 4.492862171900924e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](138/200) average pos_loss: 4.815869331359863\u001b[0m\n",
      "\u001b[34m[proc 0][Train](138/200) average neg_loss: 1.1912989020347595\u001b[0m\n",
      "\u001b[34m[proc 0][Train](138/200) average loss: 3.003584146499634\u001b[0m\n",
      "\u001b[34m[proc 0][Train](138/200) average regularization: 5.0552800530567765e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](140/200) average pos_loss: 5.142136573791504\u001b[0m\n",
      "\u001b[34m[proc 0][Train](140/200) average neg_loss: 0.9985332489013672\u001b[0m\n",
      "\u001b[34m[proc 0][Train](140/200) average loss: 3.0703349113464355\u001b[0m\n",
      "\u001b[34m[proc 0][Train](140/200) average regularization: 5.223316475166939e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](142/200) average pos_loss: 5.138864517211914\u001b[0m\n",
      "\u001b[34m[proc 0][Train](142/200) average neg_loss: 1.0547031164169312\u001b[0m\n",
      "\u001b[34m[proc 0][Train](142/200) average loss: 3.0967838764190674\u001b[0m\n",
      "\u001b[34m[proc 0][Train](142/200) average regularization: 5.270877773000393e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.084 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.039, update: 0.007\u001b[0m\n",
      "\u001b[34m[proc 0][Train](144/200) average pos_loss: 5.288041353225708\u001b[0m\n",
      "\u001b[34m[proc 0][Train](144/200) average neg_loss: 0.9516772329807281\u001b[0m\n",
      "\u001b[34m[proc 0][Train](144/200) average loss: 3.1198593378067017\u001b[0m\n",
      "\u001b[34m[proc 0][Train](144/200) average regularization: 5.0142085456172936e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.089 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.003, forward: 0.040, backward: 0.040, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](146/200) average pos_loss: 5.128804445266724\u001b[0m\n",
      "\u001b[34m[proc 0][Train](146/200) average neg_loss: 1.0289796590805054\u001b[0m\n",
      "\u001b[34m[proc 0][Train](146/200) average loss: 3.0788921117782593\u001b[0m\n",
      "\u001b[34m[proc 0][Train](146/200) average regularization: 4.922305197396781e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.100 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.021, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](148/200) average pos_loss: 4.877607583999634\u001b[0m\n",
      "\u001b[34m[proc 0][Train](148/200) average neg_loss: 1.1245091557502747\u001b[0m\n",
      "\u001b[34m[proc 0][Train](148/200) average loss: 3.001058340072632\u001b[0m\n",
      "\u001b[34m[proc 0][Train](148/200) average regularization: 5.344035889720544e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](150/200) average pos_loss: 5.503758668899536\u001b[0m\n",
      "\u001b[34m[proc 0][Train](150/200) average neg_loss: 1.1715480983257294\u001b[0m\n",
      "\u001b[34m[proc 0][Train](150/200) average loss: 3.337653398513794\u001b[0m\n",
      "\u001b[34m[proc 0][Train](150/200) average regularization: 4.975680712959729e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](152/200) average pos_loss: 5.246205568313599\u001b[0m\n",
      "\u001b[34m[proc 0][Train](152/200) average neg_loss: 1.0779292285442352\u001b[0m\n",
      "\u001b[34m[proc 0][Train](152/200) average loss: 3.1620672941207886\u001b[0m\n",
      "\u001b[34m[proc 0][Train](152/200) average regularization: 5.620134288619738e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](154/200) average pos_loss: 5.183004856109619\u001b[0m\n",
      "\u001b[34m[proc 0][Train](154/200) average neg_loss: 1.0908602476119995\u001b[0m\n",
      "\u001b[34m[proc 0][Train](154/200) average loss: 3.1369324922561646\u001b[0m\n",
      "\u001b[34m[proc 0][Train](154/200) average regularization: 4.8643327318131924e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](156/200) average pos_loss: 5.21879506111145\u001b[0m\n",
      "\u001b[34m[proc 0][Train](156/200) average neg_loss: 1.0725331008434296\u001b[0m\n",
      "\u001b[34m[proc 0][Train](156/200) average loss: 3.1456639766693115\u001b[0m\n",
      "\u001b[34m[proc 0][Train](156/200) average regularization: 5.047264312452171e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](158/200) average pos_loss: 5.262138843536377\u001b[0m\n",
      "\u001b[34m[proc 0][Train](158/200) average neg_loss: 1.1552535891532898\u001b[0m\n",
      "\u001b[34m[proc 0][Train](158/200) average loss: 3.2086962461471558\u001b[0m\n",
      "\u001b[34m[proc 0][Train](158/200) average regularization: 4.6155659219948575e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](160/200) average pos_loss: 5.144644498825073\u001b[0m\n",
      "\u001b[34m[proc 0][Train](160/200) average neg_loss: 1.2033792436122894\u001b[0m\n",
      "\u001b[34m[proc 0][Train](160/200) average loss: 3.1740119457244873\u001b[0m\n",
      "\u001b[34m[proc 0][Train](160/200) average regularization: 5.470930045703426e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](162/200) average pos_loss: 5.741542816162109\u001b[0m\n",
      "\u001b[34m[proc 0][Train](162/200) average neg_loss: 1.0164682865142822\u001b[0m\n",
      "\u001b[34m[proc 0][Train](162/200) average loss: 3.3790056705474854\u001b[0m\n",
      "\u001b[34m[proc 0][Train](162/200) average regularization: 4.9028516514226794e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.105 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.026, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](164/200) average pos_loss: 5.357571601867676\u001b[0m\n",
      "\u001b[34m[proc 0][Train](164/200) average neg_loss: 0.9640097618103027\u001b[0m\n",
      "\u001b[34m[proc 0][Train](164/200) average loss: 3.1607906818389893\u001b[0m\n",
      "\u001b[34m[proc 0][Train](164/200) average regularization: 5.767229049524758e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](166/200) average pos_loss: 5.20474648475647\u001b[0m\n",
      "\u001b[34m[proc 0][Train](166/200) average neg_loss: 1.2269590198993683\u001b[0m\n",
      "\u001b[34m[proc 0][Train](166/200) average loss: 3.2158528566360474\u001b[0m\n",
      "\u001b[34m[proc 0][Train](166/200) average regularization: 5.4604592151008546e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](168/200) average pos_loss: 5.387704372406006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](168/200) average neg_loss: 1.0688146352767944\u001b[0m\n",
      "\u001b[34m[proc 0][Train](168/200) average loss: 3.2282594442367554\u001b[0m\n",
      "\u001b[34m[proc 0][Train](168/200) average regularization: 5.180995685805101e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](170/200) average pos_loss: 5.5570151805877686\u001b[0m\n",
      "\u001b[34m[proc 0][Train](170/200) average neg_loss: 1.0938246846199036\u001b[0m\n",
      "\u001b[34m[proc 0][Train](170/200) average loss: 3.3254200220108032\u001b[0m\n",
      "\u001b[34m[proc 0][Train](170/200) average regularization: 4.995442031940911e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](172/200) average pos_loss: 5.461122512817383\u001b[0m\n",
      "\u001b[34m[proc 0][Train](172/200) average neg_loss: 1.064733862876892\u001b[0m\n",
      "\u001b[34m[proc 0][Train](172/200) average loss: 3.2629282474517822\u001b[0m\n",
      "\u001b[34m[proc 0][Train](172/200) average regularization: 4.125869963900186e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](174/200) average pos_loss: 5.2675416469573975\u001b[0m\n",
      "\u001b[34m[proc 0][Train](174/200) average neg_loss: 1.090012788772583\u001b[0m\n",
      "\u001b[34m[proc 0][Train](174/200) average loss: 3.1787772178649902\u001b[0m\n",
      "\u001b[34m[proc 0][Train](174/200) average regularization: 5.084068288851995e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.080 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.035, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](176/200) average pos_loss: 5.530467510223389\u001b[0m\n",
      "\u001b[34m[proc 0][Train](176/200) average neg_loss: 1.0654680132865906\u001b[0m\n",
      "\u001b[34m[proc 0][Train](176/200) average loss: 3.297967791557312\u001b[0m\n",
      "\u001b[34m[proc 0][Train](176/200) average regularization: 5.5583623179700226e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](178/200) average pos_loss: 5.5808188915252686\u001b[0m\n",
      "\u001b[34m[proc 0][Train](178/200) average neg_loss: 1.1129457354545593\u001b[0m\n",
      "\u001b[34m[proc 0][Train](178/200) average loss: 3.3468823432922363\u001b[0m\n",
      "\u001b[34m[proc 0][Train](178/200) average regularization: 5.527196299226489e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.105 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.026, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](180/200) average pos_loss: 5.634533405303955\u001b[0m\n",
      "\u001b[34m[proc 0][Train](180/200) average neg_loss: 1.2360199689865112\u001b[0m\n",
      "\u001b[34m[proc 0][Train](180/200) average loss: 3.4352766275405884\u001b[0m\n",
      "\u001b[34m[proc 0][Train](180/200) average regularization: 5.84519420954166e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.083 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.007\u001b[0m\n",
      "\u001b[34m[proc 0][Train](182/200) average pos_loss: 5.7796471118927\u001b[0m\n",
      "\u001b[34m[proc 0][Train](182/200) average neg_loss: 1.1758021712303162\u001b[0m\n",
      "\u001b[34m[proc 0][Train](182/200) average loss: 3.4777246713638306\u001b[0m\n",
      "\u001b[34m[proc 0][Train](182/200) average regularization: 5.4316753448802046e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.087 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.003, forward: 0.041, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](184/200) average pos_loss: 5.694804668426514\u001b[0m\n",
      "\u001b[34m[proc 0][Train](184/200) average neg_loss: 1.2181288301944733\u001b[0m\n",
      "\u001b[34m[proc 0][Train](184/200) average loss: 3.4564666748046875\u001b[0m\n",
      "\u001b[34m[proc 0][Train](184/200) average regularization: 5.477662125485949e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](186/200) average pos_loss: 5.766440391540527\u001b[0m\n",
      "\u001b[34m[proc 0][Train](186/200) average neg_loss: 1.2037226557731628\u001b[0m\n",
      "\u001b[34m[proc 0][Train](186/200) average loss: 3.4850815534591675\u001b[0m\n",
      "\u001b[34m[proc 0][Train](186/200) average regularization: 5.544153646042105e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](188/200) average pos_loss: 5.488213062286377\u001b[0m\n",
      "\u001b[34m[proc 0][Train](188/200) average neg_loss: 1.0869384407997131\u001b[0m\n",
      "\u001b[34m[proc 0][Train](188/200) average loss: 3.2875757217407227\u001b[0m\n",
      "\u001b[34m[proc 0][Train](188/200) average regularization: 6.010879405948799e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.037, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](190/200) average pos_loss: 5.632054805755615\u001b[0m\n",
      "\u001b[34m[proc 0][Train](190/200) average neg_loss: 1.1172709465026855\u001b[0m\n",
      "\u001b[34m[proc 0][Train](190/200) average loss: 3.3746628761291504\u001b[0m\n",
      "\u001b[34m[proc 0][Train](190/200) average regularization: 4.7265810280805454e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](192/200) average pos_loss: 5.395052671432495\u001b[0m\n",
      "\u001b[34m[proc 0][Train](192/200) average neg_loss: 1.1342572569847107\u001b[0m\n",
      "\u001b[34m[proc 0][Train](192/200) average loss: 3.2646548748016357\u001b[0m\n",
      "\u001b[34m[proc 0][Train](192/200) average regularization: 5.753432196797803e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](194/200) average pos_loss: 5.710200786590576\u001b[0m\n",
      "\u001b[34m[proc 0][Train](194/200) average neg_loss: 1.1495822072029114\u001b[0m\n",
      "\u001b[34m[proc 0][Train](194/200) average loss: 3.429891586303711\u001b[0m\n",
      "\u001b[34m[proc 0][Train](194/200) average regularization: 5.4568676205235533e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.100 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.021, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](196/200) average pos_loss: 5.513769626617432\u001b[0m\n",
      "\u001b[34m[proc 0][Train](196/200) average neg_loss: 1.1394105553627014\u001b[0m\n",
      "\u001b[34m[proc 0][Train](196/200) average loss: 3.326590061187744\u001b[0m\n",
      "\u001b[34m[proc 0][Train](196/200) average regularization: 5.470441101351753e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.005\u001b[0m\n",
      "\u001b[34m[proc 0][Train](198/200) average pos_loss: 5.3605101108551025\u001b[0m\n",
      "\u001b[34m[proc 0][Train](198/200) average neg_loss: 1.1047539114952087\u001b[0m\n",
      "\u001b[34m[proc 0][Train](198/200) average loss: 3.232632040977478\u001b[0m\n",
      "\u001b[34m[proc 0][Train](198/200) average regularization: 5.8894256653729826e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.081 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.036, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34m[proc 0][Train](200/200) average pos_loss: 5.749393701553345\u001b[0m\n",
      "\u001b[34m[proc 0][Train](200/200) average neg_loss: 1.0442769825458527\u001b[0m\n",
      "\u001b[34m[proc 0][Train](200/200) average loss: 3.396835446357727\u001b[0m\n",
      "\u001b[34m[proc 0][Train](200/200) average regularization: 5.37007326784078e-05\u001b[0m\n",
      "\u001b[34m[proc 0][Train] 2 steps take 0.082 seconds\u001b[0m\n",
      "\u001b[34m[proc 0]sample: 0.002, forward: 0.037, backward: 0.038, update: 0.006\u001b[0m\n",
      "\u001b[34mproc 0 takes 8.724 seconds\u001b[0m\n",
      "\u001b[34mtraining takes 14.768494129180908 seconds\u001b[0m\n",
      "\u001b[34mSave model to /opt/ml/model\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-25 08:29:05 Uploading - Uploading generated training model\n",
      "2020-11-25 08:30:17 Completed - Training job completed\n",
      "Training seconds: 307\n",
      "Billable seconds: 307\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_name='sagemaker-recsys-graph-train:latest',\n",
    "                      image_uri='002224604296.dkr.ecr.us-east-1.amazonaws.com/sagemaker-recsys-graph-train',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp6azdd0q4_algo-1-xuics_1\n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m Using backend: pytorch\n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m sys path is ['/opt/ml/code', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/src/dglke/python', '/usr/lib/python3/dist-packages']\n",
      "http://212.129.155.247/fasthan/fasthan_base.zip not found in cache, downloading to /tmp/tmpt0fe3eq_\n",
      "100% 144M/144M [00:20<00:00, 6.89MB/s] \n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m Finish download from http://212.129.155.247/fasthan/fasthan_base.zip\n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m Copy file to /root/.fastNLP/fasthan/fasthan_base\n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m loading vocabulary file /root/.fastNLP/fasthan/fasthan_base/vocab.txt\n",
      "\u001b[36malgo-1-xuics_1  |\u001b[0m Load pre-trained BERT parameters from file /root/.fastNLP/fasthan/fasthan_base/model.bin.\n",
      "\u001b[36mtmp6azdd0q4_algo-1-xuics_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Giving up, endpoint didn't launch correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c9cc4f28b8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         )\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m         self.sagemaker_client.create_endpoint(\n\u001b[0;32m-> 2708\u001b[0;31m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m         )\n\u001b[1;32m   2710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, EndpointName, EndpointConfigName, Tags)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mserving_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local.serving_port\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m8080\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0m_wait_for_serving_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;31m# the container is running and it passed the healthcheck status is now InService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IN_SERVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36m_wait_for_serving_container\u001b[0;34m(serving_port)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mHEALTH_CHECK_TIMEOUT_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Giving up, endpoint didn't launch correctly\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checking if serving container is up, attempt: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Giving up, endpoint didn't launch correctly"
     ]
    }
   ],
   "source": [
    "result = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0.2 from /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pip (python 3.6)\r\n"
     ]
    }
   ],
   "source": [
    "# 单独测试代码\n",
    "!pip install -r requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kg\n",
    "import encoding\n",
    "kg = kg.Kg('kg')\n",
    "encoder = encoding.encoding(kg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
